#!/usr/bin/env python3
"""
CX ëŒ€ì‹œë³´ë“œ Phase 2: ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ + HTML ì£¼ì…

ì‚¬ìš©ë²•:
  python3 scripts/phase2_enrich_inject.py

ë™ì‘:
  1. data/new_records.json ë¡œë“œ (Phase 1 ì‚°ì¶œë¬¼)
  2. BigQueryì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ (ì‚¬ì—…ìë²ˆí˜¸ ë§¤ì¹­)
  3. ê¸°ì¡´ ALL_RECORDS + ì‹ ê·œ ë ˆì½”ë“œ í•©ì¹˜ê¸°
  4. index.html, cs-retag-dashboard.html ì–‘ìª½ ì—…ë°ì´íŠ¸
"""

import sys
import os
import json
import re
import subprocess

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(SCRIPT_DIR)
NEW_RECORDS_JSON = os.path.join(ROOT_DIR, "data", "new_records.json")
INDEX_HTML = os.path.join(ROOT_DIR, "index.html")

# â”€â”€ í•œë„ êµ¬ê°„ ë§¤í•‘ â”€â”€
def to_limit_tier(grant_limit):
    """grant_limit(ì›) â†’ í•œë„ êµ¬ê°„ ë¬¸ìì—´"""
    if grant_limit is None:
        return "ë¯¸ë§¤ì¹­"
    try:
        v = float(grant_limit)
    except (ValueError, TypeError):
        return "ë¯¸ë§¤ì¹­"
    if v < 10_000_000:
        return "1ì²œë§Œ ë¯¸ë§Œ"
    elif v < 50_000_000:
        return "1ì²œë§Œ~5ì²œë§Œ"
    elif v < 100_000_000:
        return "5ì²œë§Œ~1ì–µ"
    elif v < 500_000_000:
        return "1ì–µ~5ì–µ"
    else:
        return "5ì–µ ì´ìƒ"


def load_new_records():
    """Phase 1 ì‚°ì¶œë¬¼ ë¡œë“œ"""
    if not os.path.exists(NEW_RECORDS_JSON):
        print(f"âŒ {os.path.relpath(NEW_RECORDS_JSON, ROOT_DIR)} ì—†ìŒ. Phase 1ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        sys.exit(1)
    with open(NEW_RECORDS_JSON, "r", encoding="utf-8") as f:
        records = json.load(f)
    return records


def load_existing_records(html_path):
    """HTMLì—ì„œ ê¸°ì¡´ ALL_RECORDS ì¶”ì¶œ"""
    with open(html_path, "r", encoding="utf-8") as f:
        content = f.read()
    match = re.search(r"const ALL_RECORDS = (\[.*?\]);", content, re.DOTALL)
    if not match:
        return [], content
    records = json.loads(match.group(1))
    return records, content


def build_corp_number_map(excel_path):
    """Excel User dataì—ì„œ userId â†’ corp_number(ìˆ«ìë§Œ) ë§¤í•‘"""
    try:
        import openpyxl
    except ImportError:
        print("  âš ï¸  openpyxl ì—†ìŒ, ì‚¬ì—…ìë²ˆí˜¸ ë§¤í•‘ ìŠ¤í‚µ")
        return {}

    # ê°€ì¥ ìµœê·¼ Excel íŒŒì¼ ì°¾ê¸°
    if not excel_path:
        data_dir = os.path.join(ROOT_DIR, "data")
        xlsx_files = sorted(
            [f for f in os.listdir(data_dir) if f.endswith(".xlsx")],
            key=lambda f: os.path.getmtime(os.path.join(data_dir, f)),
            reverse=True,
        )
        if not xlsx_files:
            print("  âš ï¸  data/ í´ë”ì— Excel íŒŒì¼ ì—†ìŒ")
            return {}
        excel_path = os.path.join(data_dir, xlsx_files[0])
        print(f"  Excel: {os.path.basename(excel_path)}")

    wb = openpyxl.load_workbook(excel_path, data_only=True)

    # UserChatì—ì„œ chatId â†’ userId ë§¤í•‘
    ws_chat = wb["UserChat"]
    chat_to_user = {}
    chat_to_corp_direct = {}
    for r in range(2, ws_chat.max_row + 1):
        chat_id = ws_chat.cell(r, 1).value
        if not chat_id:
            continue
        user_id = ws_chat.cell(r, 14).value
        if user_id:
            chat_to_user[chat_id] = user_id
        # data_onlyë¡œ ì§ì ‘ ì½íˆëŠ” ì‚¬ì—…ìë²ˆí˜¸ë„ ì‹œë„
        corp_direct = ws_chat.cell(r, 4).value
        if corp_direct and isinstance(corp_direct, str):
            chat_to_corp_direct[chat_id] = re.sub(r"[^0-9]", "", corp_direct)

    # User dataì—ì„œ userId â†’ corp_number ë§¤í•‘
    ws_user = wb["User data"]
    user_to_corp = {}
    for r in range(2, ws_user.max_row + 1):
        uid = ws_user.cell(r, 1).value
        corp = ws_user.cell(r, 6).value  # profile.corp_number
        if uid and corp:
            user_to_corp[uid] = re.sub(r"[^0-9]", "", str(corp))

    # chatId â†’ corp_number(ìˆ«ìë§Œ) ìµœì¢… ë§¤í•‘
    result = {}
    for chat_id in chat_to_user:
        # ì§ì ‘ ì½íŒ ì‚¬ì—…ìë²ˆí˜¸ ìš°ì„ 
        if chat_id in chat_to_corp_direct:
            result[chat_id] = chat_to_corp_direct[chat_id]
        else:
            user_id = chat_to_user[chat_id]
            if user_id in user_to_corp:
                result[chat_id] = user_to_corp[user_id]

    return result


def load_segment_cache():
    """data/segment_cache.jsonì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ ìºì‹œ ë¡œë“œ"""
    cache_path = os.path.join(ROOT_DIR, "data", "segment_cache.json")
    if not os.path.exists(cache_path):
        return {}
    with open(cache_path, "r", encoding="utf-8") as f:
        rows = json.load(f)
    seg_map = {}
    for row in rows:
        cid = str(row.get("corp_id", ""))
        seg_map[cid] = {
            "detailCategory": row.get("detail_category") or "ë¯¸ë§¤ì¹­",
            "stabilityStatus": row.get("stability_status") or "ë¯¸ë§¤ì¹­",
            "growthStatus": row.get("growth_status") or "ë¯¸ë§¤ì¹­",
            "limitTier": to_limit_tier(row.get("grant_limit")),
        }
    return seg_map


def fetch_segments_from_bq(corp_ids):
    """BigQueryì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì¡°íšŒ (bq CLI â†’ ìºì‹œ í´ë°±)"""
    if not corp_ids:
        return {}

    # corp_id ë¦¬ìŠ¤íŠ¸ë¥¼ SQL INì ˆë¡œ
    id_list = ", ".join(str(cid) for cid in corp_ids)
    query = f"""
    SELECT corp_id, detail_category, stability_status, growth_status, grant_limit
    FROM `gowid-prd.mart_customer_segment.segment_base`
    WHERE month_id = (SELECT MAX(month_id) FROM `gowid-prd.mart_customer_segment.segment_base`)
      AND corp_id IN ({id_list})
    """

    # bq CLI ì‹œë„
    cmd = [
        "bq", "query",
        "--use_legacy_sql=false",
        "--format=json",
        "--max_rows=10000",
        query,
    ]

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        if result.returncode == 0:
            rows = json.loads(result.stdout)
            seg_map = {}
            for row in rows:
                cid = str(row.get("corp_id", ""))
                seg_map[cid] = {
                    "detailCategory": row.get("detail_category") or "ë¯¸ë§¤ì¹­",
                    "stabilityStatus": row.get("stability_status") or "ë¯¸ë§¤ì¹­",
                    "growthStatus": row.get("growth_status") or "ë¯¸ë§¤ì¹­",
                    "limitTier": to_limit_tier(row.get("grant_limit")),
                }
            # ì„±ê³µ ì‹œ ìºì‹œ ì—…ë°ì´íŠ¸
            cache_path = os.path.join(ROOT_DIR, "data", "segment_cache.json")
            with open(cache_path, "w", encoding="utf-8") as f:
                json.dump(rows, f, ensure_ascii=False, indent=2)
            print(f"  BQ ì¿¼ë¦¬ ì„±ê³µ â†’ ìºì‹œ ì—…ë°ì´íŠ¸")
            return seg_map
    except (FileNotFoundError, subprocess.TimeoutExpired, json.JSONDecodeError):
        pass

    # í´ë°±: ìºì‹œ íŒŒì¼
    print(f"  BQ ì¿¼ë¦¬ ì‹¤íŒ¨ â†’ ìºì‹œ(segment_cache.json) ì‚¬ìš©")
    return load_segment_cache()


def enrich_records(new_records, corp_map, seg_map):
    """ì‹ ê·œ ë ˆì½”ë“œì— ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì£¼ì…"""
    matched = 0
    for rec in new_records:
        chat_id = rec["chatId"]
        corp_id = corp_map.get(chat_id)
        if corp_id and corp_id in seg_map:
            seg = seg_map[corp_id]
            rec["detailCategory"] = seg["detailCategory"]
            rec["stabilityStatus"] = seg["stabilityStatus"]
            rec["growthStatus"] = seg["growthStatus"]
            rec["limitTier"] = seg["limitTier"]
            matched += 1
    return matched


def inject_into_html(html_path, all_records, fields_to_keep):
    """HTML íŒŒì¼ì˜ ALL_RECORDSë¥¼ êµì²´"""
    with open(html_path, "r", encoding="utf-8") as f:
        content = f.read()

    # í•„ë“œ í•„í„°ë§
    filtered = []
    for r in all_records:
        filtered.append({k: r.get(k) for k in fields_to_keep})

    # JSON ì§ë ¬í™” (í•œ ì¤„)
    json_str = json.dumps(filtered, ensure_ascii=False, separators=(",", ":"))
    new_line = f"    const ALL_RECORDS = {json_str};"

    # êµì²´
    content = re.sub(
        r"    const ALL_RECORDS = \[.*?\];",
        new_line,
        content,
        count=1,
        flags=re.DOTALL,
    )

    with open(html_path, "w", encoding="utf-8") as f:
        f.write(content)


def main():
    print("ğŸš€ Phase 2: ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ + HTML ì£¼ì…\n")

    # 1. ì‹ ê·œ ë ˆì½”ë“œ ë¡œë“œ
    print("[1/5] ì‹ ê·œ ë ˆì½”ë“œ ë¡œë“œ")
    new_records = load_new_records()
    print(f"  ì‹ ê·œ: {len(new_records)}ê±´")

    if not new_records:
        print("  ìƒˆ ë ˆì½”ë“œ ì—†ìŒ. ì¢…ë£Œ.")
        return

    # 2. ì‚¬ì—…ìë²ˆí˜¸ ë§¤í•‘ ë¹Œë“œ
    print("[2/5] ì‚¬ì—…ìë²ˆí˜¸ ë§¤í•‘")
    corp_map = build_corp_number_map(None)  # ê°€ì¥ ìµœê·¼ Excel ìë™ íƒìƒ‰
    mapped = sum(1 for r in new_records if r["chatId"] in corp_map)
    print(f"  ì‚¬ì—…ìë²ˆí˜¸ ë§¤í•‘: {mapped}/{len(new_records)}ê±´")

    # 3. BQ ì„¸ê·¸ë¨¼íŠ¸ ì¡°íšŒ
    print("[3/5] BigQuery ì„¸ê·¸ë¨¼íŠ¸ ì¡°íšŒ")
    unique_corps = set(corp_map.get(r["chatId"]) for r in new_records if r["chatId"] in corp_map)
    unique_corps.discard(None)
    print(f"  ê³ ìœ  ì‚¬ì—…ìë²ˆí˜¸: {len(unique_corps)}ê°œ")

    seg_map = fetch_segments_from_bq([int(c) for c in unique_corps if c.isdigit()])
    print(f"  BQ ë§¤ì¹­: {len(seg_map)}ê°œ ë²•ì¸")

    # 4. ì„¸ê·¸ë¨¼íŠ¸ ì£¼ì…
    matched = enrich_records(new_records, corp_map, seg_map)
    print(f"  ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ ì™„ë£Œ: {matched}/{len(new_records)}ê±´")

    # 5. HTML ì£¼ì…
    print("[4/5] HTML ì£¼ì…")

    # index.html (13ê°œ í•„ë“œ)
    INDEX_FIELDS = [
        "chatId", "date", "company", "oldTag",
        "primaryTag", "secondaryTag", "confidence",
        "detailCategory", "stabilityStatus", "growthStatus", "limitTier",
        "firstAnswerSec", "closeSec",
    ]

    existing_index, _ = load_existing_records(INDEX_HTML)
    print(f"  index.html ê¸°ì¡´: {len(existing_index)}ê±´")
    all_index = existing_index + new_records
    inject_into_html(INDEX_HTML, all_index, INDEX_FIELDS)
    print(f"  index.html ì—…ë°ì´íŠ¸: {len(all_index)}ê±´")

    # ë‚ ì§œ ì—…ë°ì´íŠ¸ (í—¤ë”ì˜ ìµœì¢… ì—…ë°ì´íŠ¸ ë‚ ì§œ)
    all_dates = [r.get("date") for r in all_index if r.get("date")]
    if all_dates:
        max_date = max(all_dates)
        for html_path in [INDEX_HTML]:
            if os.path.exists(html_path):
                with open(html_path, "r", encoding="utf-8") as f:
                    content = f.read()
                # "2026. 2. 20." í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                from datetime import datetime
                dt = datetime.strptime(max_date, "%Y-%m-%d")
                date_display = f"{dt.year}. {dt.month}. {dt.day}."
                content = re.sub(
                    r'id="lastUpdateDate">[^<]+<',
                    f'id="lastUpdateDate">{date_display}<',
                    content,
                )
                with open(html_path, "w", encoding="utf-8") as f:
                    f.write(content)

    # ìš”ì•½
    print("\n[5/5] ì™„ë£Œ ìš”ì•½")
    print(f"  âœ… ì‹ ê·œ {len(new_records)}ê±´ ì¶”ê°€ (ì´ {len(all_index)}ê±´)")
    print(f"  âœ… ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­: {matched}/{len(new_records)}ê±´")
    print(f"  âœ… index.html ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    print(f"\n  ë‹¤ìŒ: git commit + push")


if __name__ == "__main__":
    main()
